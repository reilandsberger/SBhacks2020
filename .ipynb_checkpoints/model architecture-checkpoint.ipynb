{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import initializers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct the model used for classifier\n",
    "# In our case the input shape is (42,1) is the board flattened\n",
    "\n",
    "def classifier():  \n",
    "    \n",
    "    model = Sequential()\n",
    "    # 2 \"convo+pooling\" layers\n",
    "    model.add(Conv2D(filters=5, kernel_size=(3,3), strides=1, input_shape=(6,7,1)))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=10, kernel_size=(3,3), strides=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #flatten & linear layers\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(42))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Classify if there is a merger waveform, output probabilistic\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = classifier()\n",
    "\n",
    "# compile model\n",
    "ad = optimizers.Adam(lr=0.00005)\n",
    "model.compile(loss='mean_squared_error', optimizer=ad, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a 6*7 array of zeros, which represent \n",
    "def newgame():\n",
    "    n = np.zeros(42)\n",
    "    n = np.reshape(n, (6,7))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if col th column of B is full\n",
    "\n",
    "def colAvailable(B, col):\n",
    "    # start with checking if bottom (row 6) of ith column is empty \n",
    "    row = 5\n",
    "    while B[row, col] != 0:\n",
    "        row -= 1\n",
    "        if row < 0:\n",
    "            return False #column not available cuz full\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume col not a full column, meaning it has been run through the columnfull function\n",
    "# play a piece in ith column, [0,6] of B\n",
    "# player denoted with -1, 1\n",
    "\n",
    "# The function avoids modifying the original object numpy array B, returns a new object\n",
    "\n",
    "def move(B, col, player):\n",
    "    A = np.array(B)\n",
    "    # start with checking if bottom (row 6) of ith column is empty \n",
    "    row = 5\n",
    "    while A[row, col] != 0:\n",
    "        row -= 1\n",
    "    A[row, col] = player\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return all possible next board position, \n",
    "# and the associated probability of the current player winning based on the current model of network\n",
    "\n",
    "def possibilities(B, player, network):\n",
    "    pos = []\n",
    "    for col in range(7):\n",
    "        if colAvailable(B, col):\n",
    "            moved0 = move(B, col, player)\n",
    "            moved = moved0.reshape(6,7,1)\n",
    "            moved = np.asarray([moved])\n",
    "            pos.append([moved0, model.predict(moved)] )\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Written by Ryan\n",
    "\n",
    "def goodMove(B, network, player):\n",
    "    poss = possibilities(B, network, player)\n",
    "    \n",
    "    if(player == 1):\n",
    "        myIndex = 0\n",
    "    else:\n",
    "        myIndex=1\n",
    "    \n",
    "    total = 0\n",
    "    u = np.random.uniform(0,1)\n",
    "    \n",
    "    for p in poss:\n",
    "        total += p[1][0][myIndex]**3\n",
    "        \n",
    "    for i in range(len(poss)):\n",
    "        sumCubeBefore=0\n",
    "        for j in range(i):\n",
    "    \n",
    "            sumCubeBefore += poss[j][1][0][myIndex]**3\n",
    "            \n",
    "            \n",
    "        #print(\"SumCubeBefore: \" + str(sumCubeBefore))\n",
    "        #print(\"u: \" + str(u))\n",
    "        #print(\"myIndex: \" + str(myIndex))\n",
    "        #print(\"poss[i][1]\" + str(poss[i][1]))\n",
    "        #print(\"sumCubeBefore + poss[i][1][myIndex]**3/total: \" + str((sumCubeBefore + poss[i][1][0][myIndex]**3))\n",
    "        #print(\"poss[i][1][myIndex]**3: \" + str(poss[i][1][myIndex]**3))\n",
    "        #print(\"poss[i][1]**3: \" + str(poss[i][1][myIndex]**3) )\n",
    "        #print(u>=sumCubeBefore and u<=sumCubeBefore + poss[i][1][0][myIndex]**3) \n",
    "            \n",
    "            \n",
    "        if u>=sumCubeBefore/total and u<=(sumCubeBefore + poss[i][1][0][myIndex]**3)/total:\n",
    "            A=poss[i][0]\n",
    "    '''\n",
    "    print(str(A))\n",
    "    '''\n",
    "    \n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_draw(board):\n",
    "    check = 0\n",
    "    for c in range(7-3):\n",
    "        for r in range(6):\n",
    "            if board[r][c] == 0:\n",
    "                check+=1\n",
    "    \n",
    "    if check == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# board is the current position, a 2d numpy array \n",
    "# checkwin checks if any side wins\n",
    "def checkwin(board):   #returns 1 if four 1s in a row, -1 if four -1s in a row, 0 otherwise\n",
    "    #board = board[0]\n",
    "    #print(\"This is board after\" + str(board))\n",
    "    \n",
    "    isWin = 0\n",
    "\n",
    "    wincombopos = [1,1,1,1]\n",
    "    wincomboneg = [-1,-1,-1,-1]\n",
    "\n",
    "    for row in board: #look for 4 of a kind on rows\n",
    "        for i in range(4):\n",
    "            if (np.array_equal(wincombopos, row[i:i+4])):\n",
    "                isWin = 1\n",
    "            elif (np.array_equal(wincomboneg, row[i:i+4])):\n",
    "                isWin = -1\n",
    "            \n",
    "    for column in np.transpose(board): #look for 4 of a kind on columns\n",
    "        for i in range(3):\n",
    "            if (np.array_equal(wincombopos, column[i:i+4])):\n",
    "                isWin = 1\n",
    "            elif (np.array_equal(wincomboneg, column[i:i+4])):\n",
    "                isWin = -1\n",
    "    \n",
    "    for ri in range(3): #row index   #look for 4 of a kind on downward sloping diagonals\n",
    "        for ci in range(4): #column index\n",
    "            diag = np.array([board[ri][ci], board[ri+1][ci+1], board[ri+2][ci+2], board[ri+3][ci+3]])\n",
    "            if (np.array_equal(wincombopos, diag)):\n",
    "                isWin = 1\n",
    "            elif (np.array_equal(wincomboneg, diag)):\n",
    "                isWin = -1\n",
    "            \n",
    "    for ri in range(3):\n",
    "        for ci in range(4):\n",
    "            diag = np.array([board[ri+3][ci], board[ri+2][ci+1], board[ri+1][ci+2], board[ri][ci+3]])\n",
    "            if (np.array_equal(wincombopos, diag)):\n",
    "                isWin = 1\n",
    "            if (np.array_equal(wincomboneg, diag)):\n",
    "                isWin = -1\n",
    "\n",
    "    return isWin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# player1 goes first\n",
    "\n",
    "def game(network, player1):\n",
    "    B = newgame()\n",
    "    step = 0\n",
    "    boards = []\n",
    "    probs = []\n",
    "    \n",
    "    if player1 == 1:\n",
    "        player2 = -1\n",
    "    else:\n",
    "        player2 = 1\n",
    "    \n",
    "    # keep playing as long as no one winning\n",
    "    while checkwin(B) == 0 and check_draw(B) != True:\n",
    "        step += 1\n",
    "        '''\n",
    "        print()\n",
    "        print(\"Step \", step)\n",
    "        '''\n",
    "        if (step % 2) == 0: # odd step player1 moves, otherwise player2 moves\n",
    "            B = goodMove(B, player2, network)\n",
    "        else:\n",
    "            B = goodMove(B, player1, network)\n",
    "        B0 = B.reshape(6,7,1)\n",
    "        boards.append(B0)\n",
    "    \n",
    "    # try linear function first\n",
    "    if checkwin(B) != 0:\n",
    "        prob = np.arange(0.5, 1, 0.5/step) + 0.5/step\n",
    "    else:\n",
    "        prob = np.full(step, .5)\n",
    "    \n",
    "    X = boards\n",
    "    Y = np.concatenate((prob,1-prob)).reshape(step,2)\n",
    "        \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of training data to generate \n",
    "\n",
    "def generateData(N, network, player1):\n",
    "    X = np.asarray([])\n",
    "    Y = np.asarray([])\n",
    "    for i in range(N):\n",
    "        g = game(model, 1)\n",
    "        if i == 0:\n",
    "            X = g[0]\n",
    "            Y = np.asarray(g[1])\n",
    "        else:\n",
    "            X= X +g[0]\n",
    "            Y = np.concatenate((Y, np.asarray(g[1])))     \n",
    "        \n",
    "    return np.asarray(X), np.asarray(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X,Y = generateData(N, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use  21364 training data.\n"
     ]
    }
   ],
   "source": [
    "print(\"We use \", len(X), \"training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "Xtest,Ytest = generateData(N, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use  2202 test data.\n"
     ]
    }
   ],
   "source": [
    "print(\"We use \", len(Xtest), \"test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the pre-trained classifier\n",
    "model.save('model0.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21364/21364 [==============================] - 0s 15us/step\n",
      "Before training:\n",
      "train loss: 0.09155864342335703\n",
      "train accuracy: 0.5164295075940095\n",
      "\n",
      "2202/2202 [==============================] - 0s 15us/step\n",
      "Before training\n",
      "Test loss: 0.09216086397947343\n",
      "Test accuracy: 0.48819255227938657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre_train score record\n",
    "pre_score = model.evaluate(X, Y, verbose=1)\n",
    "print(\"Before training:\")\n",
    "print('train loss:', pre_score[0])\n",
    "print('train accuracy:', pre_score[1])\n",
    "print()\n",
    "\n",
    "# Pre_test score record\n",
    "pre_score = model.evaluate(Xtest, Ytest, verbose=1)\n",
    "print(\"Before training\")\n",
    "print('Test loss:', pre_score[0])\n",
    "print('Test accuracy:', pre_score[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "def learnOnData(X, Y, model):\n",
    "    epoch = 100\n",
    "    batch_size = 5\n",
    "\n",
    "    earlystopping_callback = EarlyStopping(monitor='val_acc',verbose=1,min_delta=0.5,patience=30,baseline=None)\n",
    "\n",
    "    history = model.fit(X, Y, validation_split = 0.20, batch_size=batch_size, epochs=epoch, verbose=1,\n",
    "                   callbacks=[earlystopping_callback])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance and Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2202/2202 [==============================] - 0s 18us/step\n",
      "After training:\n",
      "Test loss: 0.08898158756496688\n",
      "Test accuracy: 0.7252497728795598\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(Xtest, Ytest, verbose=1)\n",
    "print(\"After training:\")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigDaddyLearning(model):\n",
    "    learningCycles = 35\n",
    "    \n",
    "    for i in range(learningCycles):\n",
    "        N = 7000\n",
    "        X,Y = generateData(N, model, 1)\n",
    "        model = learnOnData(X, Y, model)\n",
    "        print(\"Done with training cycle \" + str(i+1))\n",
    "        \n",
    "    return model     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119312 samples, validate on 29829 samples\n",
      "Epoch 1/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0884 - acc: 0.7305 - val_loss: 0.0883 - val_acc: 0.7633\n",
      "Epoch 2/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7398 - val_loss: 0.0883 - val_acc: 0.7573\n",
      "Epoch 3/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7441 - val_loss: 0.0883 - val_acc: 0.7473\n",
      "Epoch 4/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7464 - val_loss: 0.0883 - val_acc: 0.7468\n",
      "Epoch 5/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7488 - val_loss: 0.0883 - val_acc: 0.7329\n",
      "Epoch 6/100\n",
      "119312/119312 [==============================] - 24s 205us/step - loss: 0.0883 - acc: 0.7494 - val_loss: 0.0883 - val_acc: 0.7481\n",
      "Epoch 7/100\n",
      "119312/119312 [==============================] - 24s 205us/step - loss: 0.0883 - acc: 0.7516 - val_loss: 0.0883 - val_acc: 0.7585\n",
      "Epoch 8/100\n",
      "119312/119312 [==============================] - 25s 206us/step - loss: 0.0883 - acc: 0.7515 - val_loss: 0.0883 - val_acc: 0.7714\n",
      "Epoch 9/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7542 - val_loss: 0.0883 - val_acc: 0.7435\n",
      "Epoch 10/100\n",
      "119312/119312 [==============================] - 24s 205us/step - loss: 0.0883 - acc: 0.7545 - val_loss: 0.0883 - val_acc: 0.7394\n",
      "Epoch 11/100\n",
      "119312/119312 [==============================] - 24s 205us/step - loss: 0.0883 - acc: 0.7543 - val_loss: 0.0883 - val_acc: 0.7463\n",
      "Epoch 12/100\n",
      "119312/119312 [==============================] - 25s 206us/step - loss: 0.0883 - acc: 0.7544 - val_loss: 0.0883 - val_acc: 0.7591\n",
      "Epoch 13/100\n",
      "119312/119312 [==============================] - 24s 205us/step - loss: 0.0883 - acc: 0.7549 - val_loss: 0.0883 - val_acc: 0.7711\n",
      "Epoch 14/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7562 - val_loss: 0.0883 - val_acc: 0.7480\n",
      "Epoch 15/100\n",
      "119312/119312 [==============================] - 24s 204us/step - loss: 0.0883 - acc: 0.7559 - val_loss: 0.0883 - val_acc: 0.7566\n",
      "Epoch 16/100\n",
      "119312/119312 [==============================] - 25s 208us/step - loss: 0.0883 - acc: 0.7555 - val_loss: 0.0883 - val_acc: 0.7630\n",
      "Epoch 17/100\n",
      "119312/119312 [==============================] - 25s 211us/step - loss: 0.0883 - acc: 0.7567 - val_loss: 0.0883 - val_acc: 0.7577\n",
      "Epoch 18/100\n",
      "119312/119312 [==============================] - 25s 212us/step - loss: 0.0883 - acc: 0.7570 - val_loss: 0.0883 - val_acc: 0.7578\n",
      "Epoch 19/100\n",
      "119312/119312 [==============================] - 25s 209us/step - loss: 0.0883 - acc: 0.7571 - val_loss: 0.0883 - val_acc: 0.7682\n",
      "Epoch 20/100\n",
      "119312/119312 [==============================] - 25s 209us/step - loss: 0.0883 - acc: 0.7582 - val_loss: 0.0883 - val_acc: 0.7615\n",
      "Epoch 21/100\n",
      "119312/119312 [==============================] - 25s 209us/step - loss: 0.0883 - acc: 0.7575 - val_loss: 0.0883 - val_acc: 0.7756\n",
      "Epoch 22/100\n",
      "119312/119312 [==============================] - 25s 212us/step - loss: 0.0883 - acc: 0.7591 - val_loss: 0.0883 - val_acc: 0.7597\n",
      "Epoch 23/100\n",
      "119312/119312 [==============================] - 25s 213us/step - loss: 0.0883 - acc: 0.7598 - val_loss: 0.0883 - val_acc: 0.7575\n",
      "Epoch 24/100\n",
      "119312/119312 [==============================] - 25s 214us/step - loss: 0.0883 - acc: 0.7597 - val_loss: 0.0883 - val_acc: 0.7622\n",
      "Epoch 25/100\n",
      "119312/119312 [==============================] - 26s 214us/step - loss: 0.0883 - acc: 0.7602 - val_loss: 0.0883 - val_acc: 0.7605\n",
      "Epoch 26/100\n",
      "119312/119312 [==============================] - 26s 214us/step - loss: 0.0883 - acc: 0.7596 - val_loss: 0.0883 - val_acc: 0.7669\n",
      "Epoch 27/100\n",
      "119312/119312 [==============================] - 26s 214us/step - loss: 0.0883 - acc: 0.7605 - val_loss: 0.0883 - val_acc: 0.7609\n",
      "Epoch 28/100\n",
      "119312/119312 [==============================] - 26s 217us/step - loss: 0.0883 - acc: 0.7608 - val_loss: 0.0883 - val_acc: 0.7530\n",
      "Epoch 29/100\n",
      "119312/119312 [==============================] - 26s 218us/step - loss: 0.0883 - acc: 0.7599 - val_loss: 0.0883 - val_acc: 0.7726\n",
      "Epoch 30/100\n",
      "119312/119312 [==============================] - 26s 215us/step - loss: 0.0883 - acc: 0.7616 - val_loss: 0.0883 - val_acc: 0.7610\n",
      "Epoch 31/100\n",
      "119312/119312 [==============================] - 26s 216us/step - loss: 0.0883 - acc: 0.7602 - val_loss: 0.0883 - val_acc: 0.7611\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 1\n",
      "Train on 119880 samples, validate on 29971 samples\n",
      "Epoch 1/100\n",
      "119880/119880 [==============================] - 25s 208us/step - loss: 0.0882 - acc: 0.7618 - val_loss: 0.0888 - val_acc: 0.7545\n",
      "Epoch 2/100\n",
      "119880/119880 [==============================] - 26s 213us/step - loss: 0.0882 - acc: 0.7622 - val_loss: 0.0888 - val_acc: 0.7514\n",
      "Epoch 3/100\n",
      "119880/119880 [==============================] - 25s 205us/step - loss: 0.0882 - acc: 0.7610 - val_loss: 0.0888 - val_acc: 0.7728\n",
      "Epoch 4/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7620 - val_loss: 0.0888 - val_acc: 0.7570\n",
      "Epoch 5/100\n",
      "119880/119880 [==============================] - 24s 204us/step - loss: 0.0882 - acc: 0.7618 - val_loss: 0.0888 - val_acc: 0.7656\n",
      "Epoch 6/100\n",
      "119880/119880 [==============================] - 25s 206us/step - loss: 0.0882 - acc: 0.7626 - val_loss: 0.0888 - val_acc: 0.7600\n",
      "Epoch 7/100\n",
      "119880/119880 [==============================] - 25s 205us/step - loss: 0.0882 - acc: 0.7621 - val_loss: 0.0888 - val_acc: 0.7653\n",
      "Epoch 8/100\n",
      "119880/119880 [==============================] - 25s 206us/step - loss: 0.0882 - acc: 0.7631 - val_loss: 0.0888 - val_acc: 0.7529\n",
      "Epoch 9/100\n",
      "119880/119880 [==============================] - 25s 206us/step - loss: 0.0882 - acc: 0.7628 - val_loss: 0.0888 - val_acc: 0.7524\n",
      "Epoch 10/100\n",
      "119880/119880 [==============================] - 25s 206us/step - loss: 0.0882 - acc: 0.7627 - val_loss: 0.0888 - val_acc: 0.7554\n",
      "Epoch 11/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7629 - val_loss: 0.0888 - val_acc: 0.7599\n",
      "Epoch 12/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7626 - val_loss: 0.0888 - val_acc: 0.7828\n",
      "Epoch 13/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7635 - val_loss: 0.0888 - val_acc: 0.7702\n",
      "Epoch 14/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7635 - val_loss: 0.0888 - val_acc: 0.7712\n",
      "Epoch 15/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7633 - val_loss: 0.0888 - val_acc: 0.7703\n",
      "Epoch 16/100\n",
      "119880/119880 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7643 - val_loss: 0.0888 - val_acc: 0.7527\n",
      "Epoch 17/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7638 - val_loss: 0.0888 - val_acc: 0.7487\n",
      "Epoch 18/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7641 - val_loss: 0.0888 - val_acc: 0.7671\n",
      "Epoch 19/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7651 - val_loss: 0.0888 - val_acc: 0.7679\n",
      "Epoch 20/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7645 - val_loss: 0.0888 - val_acc: 0.7635\n",
      "Epoch 21/100\n",
      "119880/119880 [==============================] - 24s 204us/step - loss: 0.0882 - acc: 0.7655 - val_loss: 0.0888 - val_acc: 0.7537\n",
      "Epoch 22/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7656 - val_loss: 0.0888 - val_acc: 0.7529\n",
      "Epoch 23/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7656 - val_loss: 0.0888 - val_acc: 0.7478\n",
      "Epoch 24/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7647 - val_loss: 0.0888 - val_acc: 0.7738\n",
      "Epoch 25/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7668 - val_loss: 0.0888 - val_acc: 0.7617\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7661 - val_loss: 0.0888 - val_acc: 0.7628\n",
      "Epoch 27/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7648 - val_loss: 0.0888 - val_acc: 0.7627\n",
      "Epoch 28/100\n",
      "119880/119880 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7658 - val_loss: 0.0888 - val_acc: 0.7658\n",
      "Epoch 29/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7644 - val_loss: 0.0888 - val_acc: 0.7910\n",
      "Epoch 30/100\n",
      "119880/119880 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7663 - val_loss: 0.0888 - val_acc: 0.7729\n",
      "Epoch 31/100\n",
      "119880/119880 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7669 - val_loss: 0.0888 - val_acc: 0.7646\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 2\n",
      "Train on 119426 samples, validate on 29857 samples\n",
      "Epoch 1/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7662 - val_loss: 0.0879 - val_acc: 0.7701\n",
      "Epoch 2/100\n",
      "119426/119426 [==============================] - 24s 203us/step - loss: 0.0883 - acc: 0.7656 - val_loss: 0.0879 - val_acc: 0.7705\n",
      "Epoch 3/100\n",
      "119426/119426 [==============================] - 24s 203us/step - loss: 0.0883 - acc: 0.7655 - val_loss: 0.0879 - val_acc: 0.7810\n",
      "Epoch 4/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7666 - val_loss: 0.0880 - val_acc: 0.7522\n",
      "Epoch 5/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7659 - val_loss: 0.0879 - val_acc: 0.7622\n",
      "Epoch 6/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7656 - val_loss: 0.0879 - val_acc: 0.7759\n",
      "Epoch 7/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7673 - val_loss: 0.0879 - val_acc: 0.7552\n",
      "Epoch 8/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7658 - val_loss: 0.0879 - val_acc: 0.7634\n",
      "Epoch 9/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7663 - val_loss: 0.0879 - val_acc: 0.7619\n",
      "Epoch 10/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7660 - val_loss: 0.0879 - val_acc: 0.7672\n",
      "Epoch 11/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7663 - val_loss: 0.0879 - val_acc: 0.7644\n",
      "Epoch 12/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7661 - val_loss: 0.0879 - val_acc: 0.7560\n",
      "Epoch 13/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7667 - val_loss: 0.0879 - val_acc: 0.7634\n",
      "Epoch 14/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7662 - val_loss: 0.0879 - val_acc: 0.7695\n",
      "Epoch 15/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7663 - val_loss: 0.0879 - val_acc: 0.7771\n",
      "Epoch 16/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7667 - val_loss: 0.0879 - val_acc: 0.7533\n",
      "Epoch 17/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7660 - val_loss: 0.0879 - val_acc: 0.7648\n",
      "Epoch 18/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7656 - val_loss: 0.0879 - val_acc: 0.7676\n",
      "Epoch 19/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7672 - val_loss: 0.0879 - val_acc: 0.7662\n",
      "Epoch 20/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7663 - val_loss: 0.0880 - val_acc: 0.7592\n",
      "Epoch 21/100\n",
      "119426/119426 [==============================] - 25s 205us/step - loss: 0.0883 - acc: 0.7662 - val_loss: 0.0879 - val_acc: 0.7714\n",
      "Epoch 22/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7675 - val_loss: 0.0879 - val_acc: 0.7685\n",
      "Epoch 23/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7669 - val_loss: 0.0879 - val_acc: 0.7679\n",
      "Epoch 24/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7668 - val_loss: 0.0879 - val_acc: 0.7675\n",
      "Epoch 25/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7665 - val_loss: 0.0879 - val_acc: 0.7667\n",
      "Epoch 26/100\n",
      "119426/119426 [==============================] - 25s 207us/step - loss: 0.0883 - acc: 0.7672 - val_loss: 0.0879 - val_acc: 0.7756\n",
      "Epoch 27/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7671 - val_loss: 0.0879 - val_acc: 0.7610\n",
      "Epoch 28/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7661 - val_loss: 0.0879 - val_acc: 0.7704\n",
      "Epoch 29/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7673 - val_loss: 0.0879 - val_acc: 0.7623\n",
      "Epoch 30/100\n",
      "119426/119426 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7670 - val_loss: 0.0879 - val_acc: 0.7574\n",
      "Epoch 31/100\n",
      "119426/119426 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7672 - val_loss: 0.0879 - val_acc: 0.7667\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 3\n",
      "Train on 119742 samples, validate on 29936 samples\n",
      "Epoch 1/100\n",
      "119742/119742 [==============================] - 24s 199us/step - loss: 0.0880 - acc: 0.7670 - val_loss: 0.0884 - val_acc: 0.7709\n",
      "Epoch 2/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7676 - val_loss: 0.0884 - val_acc: 0.7514\n",
      "Epoch 3/100\n",
      "119742/119742 [==============================] - 24s 202us/step - loss: 0.0880 - acc: 0.7669 - val_loss: 0.0884 - val_acc: 0.7465\n",
      "Epoch 4/100\n",
      "119742/119742 [==============================] - 24s 202us/step - loss: 0.0880 - acc: 0.7671 - val_loss: 0.0884 - val_acc: 0.7492\n",
      "Epoch 5/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7666 - val_loss: 0.0884 - val_acc: 0.7703\n",
      "Epoch 6/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7678 - val_loss: 0.0884 - val_acc: 0.7670\n",
      "Epoch 7/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7673 - val_loss: 0.0884 - val_acc: 0.7578\n",
      "Epoch 8/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7667 - val_loss: 0.0884 - val_acc: 0.7597\n",
      "Epoch 9/100\n",
      "119742/119742 [==============================] - 24s 203us/step - loss: 0.0880 - acc: 0.7684 - val_loss: 0.0884 - val_acc: 0.7560\n",
      "Epoch 10/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7670 - val_loss: 0.0884 - val_acc: 0.7556\n",
      "Epoch 11/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7675 - val_loss: 0.0884 - val_acc: 0.7660\n",
      "Epoch 12/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7680 - val_loss: 0.0884 - val_acc: 0.7638\n",
      "Epoch 13/100\n",
      "119742/119742 [==============================] - 24s 202us/step - loss: 0.0880 - acc: 0.7682 - val_loss: 0.0884 - val_acc: 0.7559\n",
      "Epoch 14/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7676 - val_loss: 0.0884 - val_acc: 0.7785\n",
      "Epoch 15/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7684 - val_loss: 0.0884 - val_acc: 0.7601\n",
      "Epoch 16/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7683 - val_loss: 0.0884 - val_acc: 0.7647\n",
      "Epoch 17/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7690 - val_loss: 0.0884 - val_acc: 0.7622\n",
      "Epoch 18/100\n",
      "119742/119742 [==============================] - 24s 203us/step - loss: 0.0880 - acc: 0.7677 - val_loss: 0.0884 - val_acc: 0.7627\n",
      "Epoch 19/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7689 - val_loss: 0.0884 - val_acc: 0.7530\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119742/119742 [==============================] - 24s 200us/step - loss: 0.0880 - acc: 0.7675 - val_loss: 0.0884 - val_acc: 0.7608\n",
      "Epoch 21/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7695 - val_loss: 0.0884 - val_acc: 0.7508\n",
      "Epoch 22/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7681 - val_loss: 0.0884 - val_acc: 0.7643\n",
      "Epoch 23/100\n",
      "119742/119742 [==============================] - 24s 202us/step - loss: 0.0880 - acc: 0.7682 - val_loss: 0.0884 - val_acc: 0.7591\n",
      "Epoch 24/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7683 - val_loss: 0.0884 - val_acc: 0.7574\n",
      "Epoch 25/100\n",
      "119742/119742 [==============================] - 24s 203us/step - loss: 0.0880 - acc: 0.7691 - val_loss: 0.0884 - val_acc: 0.7531\n",
      "Epoch 26/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7681 - val_loss: 0.0884 - val_acc: 0.7558\n",
      "Epoch 27/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7694 - val_loss: 0.0884 - val_acc: 0.7543\n",
      "Epoch 28/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7678 - val_loss: 0.0884 - val_acc: 0.7692\n",
      "Epoch 29/100\n",
      "119742/119742 [==============================] - 24s 202us/step - loss: 0.0880 - acc: 0.7685 - val_loss: 0.0884 - val_acc: 0.7595\n",
      "Epoch 30/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7688 - val_loss: 0.0884 - val_acc: 0.7539\n",
      "Epoch 31/100\n",
      "119742/119742 [==============================] - 24s 201us/step - loss: 0.0880 - acc: 0.7691 - val_loss: 0.0884 - val_acc: 0.7572\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 4\n",
      "Train on 119970 samples, validate on 29993 samples\n",
      "Epoch 1/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7645 - val_loss: 0.0882 - val_acc: 0.7591\n",
      "Epoch 2/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7636 - val_loss: 0.0882 - val_acc: 0.7496\n",
      "Epoch 3/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7626 - val_loss: 0.0882 - val_acc: 0.7356\n",
      "Epoch 4/100\n",
      "119970/119970 [==============================] - 24s 200us/step - loss: 0.0882 - acc: 0.7631 - val_loss: 0.0882 - val_acc: 0.7674\n",
      "Epoch 5/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7635 - val_loss: 0.0882 - val_acc: 0.7549\n",
      "Epoch 6/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7631 - val_loss: 0.0882 - val_acc: 0.7698\n",
      "Epoch 7/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7629 - val_loss: 0.0882 - val_acc: 0.7628\n",
      "Epoch 8/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7635 - val_loss: 0.0882 - val_acc: 0.7510\n",
      "Epoch 9/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7641 - val_loss: 0.0882 - val_acc: 0.7627\n",
      "Epoch 10/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7644 - val_loss: 0.0882 - val_acc: 0.7413\n",
      "Epoch 11/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7632 - val_loss: 0.0882 - val_acc: 0.7754\n",
      "Epoch 12/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7637 - val_loss: 0.0882 - val_acc: 0.7704\n",
      "Epoch 13/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7651 - val_loss: 0.0882 - val_acc: 0.7668\n",
      "Epoch 14/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7648 - val_loss: 0.0882 - val_acc: 0.7631\n",
      "Epoch 15/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7645 - val_loss: 0.0882 - val_acc: 0.7595\n",
      "Epoch 16/100\n",
      "119970/119970 [==============================] - 24s 200us/step - loss: 0.0882 - acc: 0.7641 - val_loss: 0.0882 - val_acc: 0.7603\n",
      "Epoch 17/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7641 - val_loss: 0.0882 - val_acc: 0.7639\n",
      "Epoch 18/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7652 - val_loss: 0.0882 - val_acc: 0.7571\n",
      "Epoch 19/100\n",
      "119970/119970 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7655 - val_loss: 0.0882 - val_acc: 0.7671\n",
      "Epoch 20/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7648 - val_loss: 0.0882 - val_acc: 0.7592\n",
      "Epoch 21/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7648 - val_loss: 0.0882 - val_acc: 0.7771\n",
      "Epoch 22/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7660 - val_loss: 0.0882 - val_acc: 0.7569\n",
      "Epoch 23/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7643 - val_loss: 0.0882 - val_acc: 0.7698\n",
      "Epoch 24/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7652 - val_loss: 0.0882 - val_acc: 0.7545\n",
      "Epoch 25/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7642 - val_loss: 0.0882 - val_acc: 0.7585\n",
      "Epoch 26/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7654 - val_loss: 0.0882 - val_acc: 0.7613\n",
      "Epoch 27/100\n",
      "119970/119970 [==============================] - 24s 201us/step - loss: 0.0882 - acc: 0.7645 - val_loss: 0.0882 - val_acc: 0.7712\n",
      "Epoch 28/100\n",
      "119970/119970 [==============================] - 24s 204us/step - loss: 0.0882 - acc: 0.7646 - val_loss: 0.0882 - val_acc: 0.7530\n",
      "Epoch 29/100\n",
      "119970/119970 [==============================] - 24s 202us/step - loss: 0.0882 - acc: 0.7653 - val_loss: 0.0882 - val_acc: 0.7554\n",
      "Epoch 30/100\n",
      "119970/119970 [==============================] - 24s 203us/step - loss: 0.0882 - acc: 0.7648 - val_loss: 0.0882 - val_acc: 0.7553\n",
      "Epoch 31/100\n",
      "119970/119970 [==============================] - 25s 205us/step - loss: 0.0882 - acc: 0.7647 - val_loss: 0.0882 - val_acc: 0.7653\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 5\n",
      "Train on 119900 samples, validate on 29975 samples\n",
      "Epoch 1/100\n",
      "119900/119900 [==============================] - 24s 201us/step - loss: 0.0878 - acc: 0.7675 - val_loss: 0.0886 - val_acc: 0.7618\n",
      "Epoch 2/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7674 - val_loss: 0.0886 - val_acc: 0.7799\n",
      "Epoch 3/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7670 - val_loss: 0.0886 - val_acc: 0.7751\n",
      "Epoch 4/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7684 - val_loss: 0.0886 - val_acc: 0.7384\n",
      "Epoch 5/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7673 - val_loss: 0.0886 - val_acc: 0.7761\n",
      "Epoch 6/100\n",
      "119900/119900 [==============================] - 24s 203us/step - loss: 0.0878 - acc: 0.7690 - val_loss: 0.0886 - val_acc: 0.7865\n",
      "Epoch 7/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7683 - val_loss: 0.0886 - val_acc: 0.7548\n",
      "Epoch 8/100\n",
      "119900/119900 [==============================] - 24s 203us/step - loss: 0.0878 - acc: 0.7680 - val_loss: 0.0886 - val_acc: 0.7632\n",
      "Epoch 9/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7678 - val_loss: 0.0886 - val_acc: 0.7815\n",
      "Epoch 10/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7692 - val_loss: 0.0886 - val_acc: 0.7613\n",
      "Epoch 11/100\n",
      "119900/119900 [==============================] - 24s 203us/step - loss: 0.0878 - acc: 0.7681 - val_loss: 0.0886 - val_acc: 0.7853\n",
      "Epoch 12/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7691 - val_loss: 0.0886 - val_acc: 0.7593\n",
      "Epoch 13/100\n",
      "119900/119900 [==============================] - 24s 203us/step - loss: 0.0878 - acc: 0.7692 - val_loss: 0.0886 - val_acc: 0.7665\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7689 - val_loss: 0.0886 - val_acc: 0.7460\n",
      "Epoch 15/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7680 - val_loss: 0.0886 - val_acc: 0.7613\n",
      "Epoch 16/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7678 - val_loss: 0.0886 - val_acc: 0.7816\n",
      "Epoch 17/100\n",
      "119900/119900 [==============================] - 24s 201us/step - loss: 0.0878 - acc: 0.7691 - val_loss: 0.0886 - val_acc: 0.7838\n",
      "Epoch 18/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7690 - val_loss: 0.0886 - val_acc: 0.7719\n",
      "Epoch 19/100\n",
      "119900/119900 [==============================] - 24s 203us/step - loss: 0.0878 - acc: 0.7691 - val_loss: 0.0886 - val_acc: 0.7716\n",
      "Epoch 20/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7697 - val_loss: 0.0886 - val_acc: 0.7703\n",
      "Epoch 21/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7691 - val_loss: 0.0886 - val_acc: 0.7712\n",
      "Epoch 22/100\n",
      "119900/119900 [==============================] - 24s 203us/step - loss: 0.0878 - acc: 0.7679 - val_loss: 0.0886 - val_acc: 0.7748\n",
      "Epoch 23/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7694 - val_loss: 0.0886 - val_acc: 0.7716\n",
      "Epoch 24/100\n",
      "119900/119900 [==============================] - 24s 201us/step - loss: 0.0878 - acc: 0.7688 - val_loss: 0.0886 - val_acc: 0.7644\n",
      "Epoch 25/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7681 - val_loss: 0.0886 - val_acc: 0.7646\n",
      "Epoch 26/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7684 - val_loss: 0.0886 - val_acc: 0.7591\n",
      "Epoch 27/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7686 - val_loss: 0.0886 - val_acc: 0.7386\n",
      "Epoch 28/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7681 - val_loss: 0.0886 - val_acc: 0.7722\n",
      "Epoch 29/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7684 - val_loss: 0.0886 - val_acc: 0.7764\n",
      "Epoch 30/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7676 - val_loss: 0.0886 - val_acc: 0.7785\n",
      "Epoch 31/100\n",
      "119900/119900 [==============================] - 24s 202us/step - loss: 0.0878 - acc: 0.7689 - val_loss: 0.0886 - val_acc: 0.7817\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 6\n",
      "Train on 120413 samples, validate on 30104 samples\n",
      "Epoch 1/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7691 - val_loss: 0.0877 - val_acc: 0.7809\n",
      "Epoch 2/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7681 - val_loss: 0.0877 - val_acc: 0.7929\n",
      "Epoch 3/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7701 - val_loss: 0.0877 - val_acc: 0.7677\n",
      "Epoch 4/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7680 - val_loss: 0.0877 - val_acc: 0.7618\n",
      "Epoch 5/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7691 - val_loss: 0.0877 - val_acc: 0.7663\n",
      "Epoch 6/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7689 - val_loss: 0.0877 - val_acc: 0.7810\n",
      "Epoch 7/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7699 - val_loss: 0.0877 - val_acc: 0.7675\n",
      "Epoch 8/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7698 - val_loss: 0.0877 - val_acc: 0.7765\n",
      "Epoch 9/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7694 - val_loss: 0.0877 - val_acc: 0.7627\n",
      "Epoch 10/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7687 - val_loss: 0.0877 - val_acc: 0.7727\n",
      "Epoch 11/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7692 - val_loss: 0.0877 - val_acc: 0.7764\n",
      "Epoch 12/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7700 - val_loss: 0.0877 - val_acc: 0.7739\n",
      "Epoch 13/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7698 - val_loss: 0.0877 - val_acc: 0.7704\n",
      "Epoch 14/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7703 - val_loss: 0.0877 - val_acc: 0.7599\n",
      "Epoch 15/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7691 - val_loss: 0.0877 - val_acc: 0.7677\n",
      "Epoch 16/100\n",
      "120413/120413 [==============================] - 25s 204us/step - loss: 0.0881 - acc: 0.7697 - val_loss: 0.0877 - val_acc: 0.7849\n",
      "Epoch 17/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7709 - val_loss: 0.0877 - val_acc: 0.7667\n",
      "Epoch 18/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7701 - val_loss: 0.0877 - val_acc: 0.7689\n",
      "Epoch 19/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7702 - val_loss: 0.0877 - val_acc: 0.7493\n",
      "Epoch 20/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7696 - val_loss: 0.0877 - val_acc: 0.7841\n",
      "Epoch 21/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7704 - val_loss: 0.0877 - val_acc: 0.7725\n",
      "Epoch 22/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7713 - val_loss: 0.0877 - val_acc: 0.7499\n",
      "Epoch 23/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7692 - val_loss: 0.0877 - val_acc: 0.7870\n",
      "Epoch 24/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7713 - val_loss: 0.0877 - val_acc: 0.7644\n",
      "Epoch 25/100\n",
      "120413/120413 [==============================] - 24s 203us/step - loss: 0.0881 - acc: 0.7698 - val_loss: 0.0877 - val_acc: 0.7622\n",
      "Epoch 26/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7700 - val_loss: 0.0877 - val_acc: 0.7656\n",
      "Epoch 27/100\n",
      "120413/120413 [==============================] - 24s 203us/step - loss: 0.0881 - acc: 0.7696 - val_loss: 0.0877 - val_acc: 0.7711\n",
      "Epoch 28/100\n",
      "120413/120413 [==============================] - 24s 202us/step - loss: 0.0881 - acc: 0.7695 - val_loss: 0.0877 - val_acc: 0.7784\n",
      "Epoch 29/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7702 - val_loss: 0.0877 - val_acc: 0.7731\n",
      "Epoch 30/100\n",
      "120413/120413 [==============================] - 24s 203us/step - loss: 0.0881 - acc: 0.7704 - val_loss: 0.0877 - val_acc: 0.7663\n",
      "Epoch 31/100\n",
      "120413/120413 [==============================] - 24s 201us/step - loss: 0.0881 - acc: 0.7701 - val_loss: 0.0877 - val_acc: 0.7593\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 7\n",
      "Train on 119803 samples, validate on 29951 samples\n",
      "Epoch 1/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7707 - val_loss: 0.0882 - val_acc: 0.7586\n",
      "Epoch 2/100\n",
      "119803/119803 [==============================] - 24s 203us/step - loss: 0.0883 - acc: 0.7707 - val_loss: 0.0882 - val_acc: 0.7735\n",
      "Epoch 3/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7701 - val_loss: 0.0882 - val_acc: 0.7876\n",
      "Epoch 4/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7709 - val_loss: 0.0882 - val_acc: 0.7672\n",
      "Epoch 5/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7702 - val_loss: 0.0882 - val_acc: 0.7674\n",
      "Epoch 6/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7709 - val_loss: 0.0882 - val_acc: 0.7720\n",
      "Epoch 7/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7716 - val_loss: 0.0882 - val_acc: 0.7706\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7706 - val_loss: 0.0882 - val_acc: 0.7742\n",
      "Epoch 9/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7714 - val_loss: 0.0882 - val_acc: 0.7625\n",
      "Epoch 10/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7698 - val_loss: 0.0882 - val_acc: 0.7673\n",
      "Epoch 11/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7703 - val_loss: 0.0882 - val_acc: 0.7871\n",
      "Epoch 12/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7714 - val_loss: 0.0882 - val_acc: 0.7689\n",
      "Epoch 13/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7714 - val_loss: 0.0882 - val_acc: 0.7555\n",
      "Epoch 14/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7709 - val_loss: 0.0882 - val_acc: 0.7668\n",
      "Epoch 15/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7704 - val_loss: 0.0882 - val_acc: 0.7787\n",
      "Epoch 16/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7719 - val_loss: 0.0882 - val_acc: 0.7583\n",
      "Epoch 17/100\n",
      "119803/119803 [==============================] - 24s 203us/step - loss: 0.0883 - acc: 0.7705 - val_loss: 0.0882 - val_acc: 0.7847\n",
      "Epoch 18/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7714 - val_loss: 0.0882 - val_acc: 0.7447\n",
      "Epoch 19/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7707 - val_loss: 0.0882 - val_acc: 0.7859\n",
      "Epoch 20/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7712 - val_loss: 0.0882 - val_acc: 0.7722\n",
      "Epoch 21/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7713 - val_loss: 0.0882 - val_acc: 0.7650\n",
      "Epoch 22/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7710 - val_loss: 0.0882 - val_acc: 0.7745\n",
      "Epoch 23/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7712 - val_loss: 0.0882 - val_acc: 0.7631\n",
      "Epoch 24/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7699 - val_loss: 0.0882 - val_acc: 0.7977\n",
      "Epoch 25/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7715 - val_loss: 0.0882 - val_acc: 0.7721\n",
      "Epoch 26/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7724 - val_loss: 0.0882 - val_acc: 0.7684\n",
      "Epoch 27/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7705 - val_loss: 0.0882 - val_acc: 0.7633\n",
      "Epoch 28/100\n",
      "119803/119803 [==============================] - 24s 202us/step - loss: 0.0883 - acc: 0.7706 - val_loss: 0.0882 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7708 - val_loss: 0.0882 - val_acc: 0.7816\n",
      "Epoch 30/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7720 - val_loss: 0.0882 - val_acc: 0.7484\n",
      "Epoch 31/100\n",
      "119803/119803 [==============================] - 24s 201us/step - loss: 0.0883 - acc: 0.7700 - val_loss: 0.0882 - val_acc: 0.78090s - loss: 0.088\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 8\n",
      "Train on 119254 samples, validate on 29814 samples\n",
      "Epoch 1/100\n",
      "119254/119254 [==============================] - 24s 205us/step - loss: 0.0884 - acc: 0.7678 - val_loss: 0.0880 - val_acc: 0.7611\n",
      "Epoch 2/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7660 - val_loss: 0.0880 - val_acc: 0.7691\n",
      "Epoch 3/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7668 - val_loss: 0.0880 - val_acc: 0.7541\n",
      "Epoch 4/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7671 - val_loss: 0.0880 - val_acc: 0.7692\n",
      "Epoch 5/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7678 - val_loss: 0.0880 - val_acc: 0.7532\n",
      "Epoch 6/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7668 - val_loss: 0.0880 - val_acc: 0.7704\n",
      "Epoch 7/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7680 - val_loss: 0.0880 - val_acc: 0.7665\n",
      "Epoch 8/100\n",
      "119254/119254 [==============================] - 24s 203us/step - loss: 0.0884 - acc: 0.7671 - val_loss: 0.0880 - val_acc: 0.7715\n",
      "Epoch 9/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7679 - val_loss: 0.0880 - val_acc: 0.7690\n",
      "Epoch 10/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7675 - val_loss: 0.0880 - val_acc: 0.7834\n",
      "Epoch 11/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7681 - val_loss: 0.0880 - val_acc: 0.7483\n",
      "Epoch 12/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7678 - val_loss: 0.0880 - val_acc: 0.7793\n",
      "Epoch 13/100\n",
      "119254/119254 [==============================] - 24s 203us/step - loss: 0.0884 - acc: 0.7684 - val_loss: 0.0880 - val_acc: 0.7672\n",
      "Epoch 14/100\n",
      "119254/119254 [==============================] - 24s 203us/step - loss: 0.0884 - acc: 0.7676 - val_loss: 0.0880 - val_acc: 0.7754\n",
      "Epoch 15/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7680 - val_loss: 0.0880 - val_acc: 0.7600\n",
      "Epoch 16/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7680 - val_loss: 0.0880 - val_acc: 0.7659\n",
      "Epoch 17/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7674 - val_loss: 0.0880 - val_acc: 0.7833\n",
      "Epoch 18/100\n",
      "119254/119254 [==============================] - 24s 203us/step - loss: 0.0884 - acc: 0.7681 - val_loss: 0.0880 - val_acc: 0.7734\n",
      "Epoch 19/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7683 - val_loss: 0.0880 - val_acc: 0.7727\n",
      "Epoch 20/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7692 - val_loss: 0.0880 - val_acc: 0.7743\n",
      "Epoch 21/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7682 - val_loss: 0.0880 - val_acc: 0.7582\n",
      "Epoch 22/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7680 - val_loss: 0.0880 - val_acc: 0.7620\n",
      "Epoch 23/100\n",
      "119254/119254 [==============================] - 24s 203us/step - loss: 0.0884 - acc: 0.7681 - val_loss: 0.0880 - val_acc: 0.7589\n",
      "Epoch 24/100\n",
      "119254/119254 [==============================] - 24s 203us/step - loss: 0.0884 - acc: 0.7684 - val_loss: 0.0880 - val_acc: 0.7694\n",
      "Epoch 25/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7689 - val_loss: 0.0880 - val_acc: 0.7497\n",
      "Epoch 26/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7682 - val_loss: 0.0880 - val_acc: 0.7562\n",
      "Epoch 27/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7676 - val_loss: 0.0880 - val_acc: 0.7709\n",
      "Epoch 28/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7690 - val_loss: 0.0880 - val_acc: 0.7548\n",
      "Epoch 29/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7672 - val_loss: 0.0880 - val_acc: 0.7758\n",
      "Epoch 30/100\n",
      "119254/119254 [==============================] - 24s 201us/step - loss: 0.0884 - acc: 0.7682 - val_loss: 0.0880 - val_acc: 0.7684\n",
      "Epoch 31/100\n",
      "119254/119254 [==============================] - 24s 202us/step - loss: 0.0884 - acc: 0.7680 - val_loss: 0.0880 - val_acc: 0.7819\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 9\n",
      "Train on 119720 samples, validate on 29931 samples\n",
      "Epoch 1/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7660 - val_loss: 0.0883 - val_acc: 0.7630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7670 - val_loss: 0.0884 - val_acc: 0.7589\n",
      "Epoch 3/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7670 - val_loss: 0.0883 - val_acc: 0.7710\n",
      "Epoch 4/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7685 - val_loss: 0.0884 - val_acc: 0.7585\n",
      "Epoch 5/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7669 - val_loss: 0.0883 - val_acc: 0.7623\n",
      "Epoch 6/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7683 - val_loss: 0.0883 - val_acc: 0.7751\n",
      "Epoch 7/100\n",
      "119720/119720 [==============================] - 24s 200us/step - loss: 0.0882 - acc: 0.7692 - val_loss: 0.0884 - val_acc: 0.7583\n",
      "Epoch 8/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7686 - val_loss: 0.0884 - val_acc: 0.7822\n",
      "Epoch 9/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7692 - val_loss: 0.0883 - val_acc: 0.7652\n",
      "Epoch 10/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7683 - val_loss: 0.0883 - val_acc: 0.7816\n",
      "Epoch 11/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7692 - val_loss: 0.0884 - val_acc: 0.7743\n",
      "Epoch 12/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7694 - val_loss: 0.0883 - val_acc: 0.7608\n",
      "Epoch 13/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7681 - val_loss: 0.0884 - val_acc: 0.7411\n",
      "Epoch 14/100\n",
      "119720/119720 [==============================] - 24s 199us/step - loss: 0.0882 - acc: 0.7687 - val_loss: 0.0883 - val_acc: 0.7709\n",
      "Epoch 15/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7691 - val_loss: 0.0883 - val_acc: 0.7628\n",
      "Epoch 16/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7692 - val_loss: 0.0884 - val_acc: 0.7762\n",
      "Epoch 17/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7690 - val_loss: 0.0883 - val_acc: 0.7636\n",
      "Epoch 18/100\n",
      "119720/119720 [==============================] - 24s 199us/step - loss: 0.0882 - acc: 0.7688 - val_loss: 0.0884 - val_acc: 0.7791\n",
      "Epoch 19/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7688 - val_loss: 0.0883 - val_acc: 0.7705\n",
      "Epoch 20/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7691 - val_loss: 0.0884 - val_acc: 0.7516\n",
      "Epoch 21/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7688 - val_loss: 0.0884 - val_acc: 0.7736\n",
      "Epoch 22/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7684 - val_loss: 0.0884 - val_acc: 0.7855\n",
      "Epoch 23/100\n",
      "119720/119720 [==============================] - 24s 199us/step - loss: 0.0882 - acc: 0.7690 - val_loss: 0.0884 - val_acc: 0.7695\n",
      "Epoch 24/100\n",
      "119720/119720 [==============================] - 24s 200us/step - loss: 0.0882 - acc: 0.7693 - val_loss: 0.0883 - val_acc: 0.7651\n",
      "Epoch 25/100\n",
      "119720/119720 [==============================] - 24s 199us/step - loss: 0.0882 - acc: 0.7691 - val_loss: 0.0883 - val_acc: 0.7509\n",
      "Epoch 26/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7692 - val_loss: 0.0883 - val_acc: 0.7753\n",
      "Epoch 27/100\n",
      "119720/119720 [==============================] - 25s 213us/step - loss: 0.0882 - acc: 0.7687 - val_loss: 0.0884 - val_acc: 0.7811\n",
      "Epoch 28/100\n",
      "119720/119720 [==============================] - 24s 197us/step - loss: 0.0882 - acc: 0.7694 - val_loss: 0.0883 - val_acc: 0.7657\n",
      "Epoch 29/100\n",
      "119720/119720 [==============================] - 24s 198us/step - loss: 0.0882 - acc: 0.7688 - val_loss: 0.0884 - val_acc: 0.7756\n",
      "Epoch 30/100\n",
      "119720/119720 [==============================] - 24s 199us/step - loss: 0.0882 - acc: 0.7691 - val_loss: 0.0884 - val_acc: 0.7796\n",
      "Epoch 31/100\n",
      "119720/119720 [==============================] - 24s 199us/step - loss: 0.0882 - acc: 0.7690 - val_loss: 0.0883 - val_acc: 0.7812\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 10\n",
      "Train on 119001 samples, validate on 29751 samples\n",
      "Epoch 1/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7710 - val_loss: 0.0888 - val_acc: 0.7692\n",
      "Epoch 2/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7709 - val_loss: 0.0888 - val_acc: 0.7616\n",
      "Epoch 3/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7688 - val_loss: 0.0888 - val_acc: 0.7820\n",
      "Epoch 4/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7705 - val_loss: 0.0888 - val_acc: 0.7627\n",
      "Epoch 5/100\n",
      "119001/119001 [==============================] - 24s 200us/step - loss: 0.0883 - acc: 0.7702 - val_loss: 0.0888 - val_acc: 0.7719\n",
      "Epoch 6/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7698 - val_loss: 0.0888 - val_acc: 0.7558\n",
      "Epoch 7/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7694 - val_loss: 0.0888 - val_acc: 0.7730\n",
      "Epoch 8/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7706 - val_loss: 0.0888 - val_acc: 0.7719\n",
      "Epoch 9/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7695 - val_loss: 0.0888 - val_acc: 0.7843\n",
      "Epoch 10/100\n",
      "119001/119001 [==============================] - 24s 200us/step - loss: 0.0883 - acc: 0.7704 - val_loss: 0.0888 - val_acc: 0.7605\n",
      "Epoch 11/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7693 - val_loss: 0.0888 - val_acc: 0.7777\n",
      "Epoch 12/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7695 - val_loss: 0.0888 - val_acc: 0.7735\n",
      "Epoch 13/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7691 - val_loss: 0.0888 - val_acc: 0.7756\n",
      "Epoch 14/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7700 - val_loss: 0.0888 - val_acc: 0.7678\n",
      "Epoch 15/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7689 - val_loss: 0.0888 - val_acc: 0.7622\n",
      "Epoch 16/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7697 - val_loss: 0.0888 - val_acc: 0.7630\n",
      "Epoch 17/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7696 - val_loss: 0.0888 - val_acc: 0.7491\n",
      "Epoch 18/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7689 - val_loss: 0.0888 - val_acc: 0.7709\n",
      "Epoch 19/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7695 - val_loss: 0.0888 - val_acc: 0.7660\n",
      "Epoch 20/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7696 - val_loss: 0.0888 - val_acc: 0.7647\n",
      "Epoch 21/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7695 - val_loss: 0.0888 - val_acc: 0.7621\n",
      "Epoch 22/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7687 - val_loss: 0.0888 - val_acc: 0.7661\n",
      "Epoch 23/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7704 - val_loss: 0.0888 - val_acc: 0.7520\n",
      "Epoch 24/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7696 - val_loss: 0.0888 - val_acc: 0.7566\n",
      "Epoch 25/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7697 - val_loss: 0.0888 - val_acc: 0.7595\n",
      "Epoch 26/100\n",
      "119001/119001 [==============================] - 24s 199us/step - loss: 0.0883 - acc: 0.7695 - val_loss: 0.0888 - val_acc: 0.7653\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7694 - val_loss: 0.0888 - val_acc: 0.7675\n",
      "Epoch 28/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7697 - val_loss: 0.0888 - val_acc: 0.7658\n",
      "Epoch 29/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7701 - val_loss: 0.0888 - val_acc: 0.7600\n",
      "Epoch 30/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7686 - val_loss: 0.0888 - val_acc: 0.7693\n",
      "Epoch 31/100\n",
      "119001/119001 [==============================] - 24s 198us/step - loss: 0.0883 - acc: 0.7701 - val_loss: 0.0888 - val_acc: 0.7625\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 11\n",
      "Train on 119688 samples, validate on 29922 samples\n",
      "Epoch 1/100\n",
      "119688/119688 [==============================] - 24s 198us/step - loss: 0.0885 - acc: 0.7691 - val_loss: 0.0885 - val_acc: 0.7363\n",
      "Epoch 2/100\n",
      "119688/119688 [==============================] - 24s 199us/step - loss: 0.0885 - acc: 0.7676 - val_loss: 0.0885 - val_acc: 0.7497\n",
      "Epoch 3/100\n",
      "119688/119688 [==============================] - 24s 199us/step - loss: 0.0885 - acc: 0.7682 - val_loss: 0.0885 - val_acc: 0.7607\n",
      "Epoch 4/100\n",
      "119688/119688 [==============================] - 24s 199us/step - loss: 0.0885 - acc: 0.7681 - val_loss: 0.0885 - val_acc: 0.7688\n",
      "Epoch 5/100\n",
      "119688/119688 [==============================] - 24s 199us/step - loss: 0.0885 - acc: 0.7671 - val_loss: 0.0885 - val_acc: 0.7694\n",
      "Epoch 6/100\n",
      "119688/119688 [==============================] - 26s 218us/step - loss: 0.0885 - acc: 0.7683 - val_loss: 0.0885 - val_acc: 0.7744\n",
      "Epoch 7/100\n",
      "119688/119688 [==============================] - 27s 225us/step - loss: 0.0885 - acc: 0.7669 - val_loss: 0.0885 - val_acc: 0.7663\n",
      "Epoch 8/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7683 - val_loss: 0.0885 - val_acc: 0.7736\n",
      "Epoch 9/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7686 - val_loss: 0.0885 - val_acc: 0.7418\n",
      "Epoch 10/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7670 - val_loss: 0.0885 - val_acc: 0.7602\n",
      "Epoch 11/100\n",
      "119688/119688 [==============================] - 24s 204us/step - loss: 0.0885 - acc: 0.7672 - val_loss: 0.0885 - val_acc: 0.7719\n",
      "Epoch 12/100\n",
      "119688/119688 [==============================] - 24s 202us/step - loss: 0.0885 - acc: 0.7682 - val_loss: 0.0885 - val_acc: 0.7690\n",
      "Epoch 13/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7683 - val_loss: 0.0885 - val_acc: 0.7663\n",
      "Epoch 14/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7680 - val_loss: 0.0885 - val_acc: 0.7782\n",
      "Epoch 15/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7683 - val_loss: 0.0885 - val_acc: 0.7670\n",
      "Epoch 16/100\n",
      "119688/119688 [==============================] - 24s 202us/step - loss: 0.0885 - acc: 0.7683 - val_loss: 0.0885 - val_acc: 0.7751\n",
      "Epoch 17/100\n",
      "119688/119688 [==============================] - 24s 202us/step - loss: 0.0885 - acc: 0.7683 - val_loss: 0.0885 - val_acc: 0.7715\n",
      "Epoch 18/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7675 - val_loss: 0.0885 - val_acc: 0.7740\n",
      "Epoch 19/100\n",
      "119688/119688 [==============================] - 28s 232us/step - loss: 0.0885 - acc: 0.7681 - val_loss: 0.0885 - val_acc: 0.7505\n",
      "Epoch 20/100\n",
      "119688/119688 [==============================] - 26s 214us/step - loss: 0.0885 - acc: 0.7670 - val_loss: 0.0885 - val_acc: 0.7621\n",
      "Epoch 21/100\n",
      "119688/119688 [==============================] - 26s 213us/step - loss: 0.0885 - acc: 0.7685 - val_loss: 0.0885 - val_acc: 0.7529\n",
      "Epoch 22/100\n",
      "119688/119688 [==============================] - 25s 211us/step - loss: 0.0885 - acc: 0.7673 - val_loss: 0.0885 - val_acc: 0.7854\n",
      "Epoch 23/100\n",
      "119688/119688 [==============================] - 25s 205us/step - loss: 0.0885 - acc: 0.7689 - val_loss: 0.0885 - val_acc: 0.7519\n",
      "Epoch 24/100\n",
      "119688/119688 [==============================] - 25s 205us/step - loss: 0.0885 - acc: 0.7686 - val_loss: 0.0885 - val_acc: 0.7450\n",
      "Epoch 25/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7687 - val_loss: 0.0885 - val_acc: 0.7505\n",
      "Epoch 26/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7672 - val_loss: 0.0885 - val_acc: 0.7635\n",
      "Epoch 27/100\n",
      "119688/119688 [==============================] - 24s 203us/step - loss: 0.0885 - acc: 0.7678 - val_loss: 0.0885 - val_acc: 0.7540\n",
      "Epoch 28/100\n",
      "119688/119688 [==============================] - 24s 201us/step - loss: 0.0885 - acc: 0.7676 - val_loss: 0.0885 - val_acc: 0.7806\n",
      "Epoch 29/100\n",
      "119688/119688 [==============================] - 24s 202us/step - loss: 0.0885 - acc: 0.7687 - val_loss: 0.0885 - val_acc: 0.7795\n",
      "Epoch 30/100\n",
      "119688/119688 [==============================] - 25s 213us/step - loss: 0.0885 - acc: 0.7678 - val_loss: 0.0885 - val_acc: 0.7880\n",
      "Epoch 31/100\n",
      "119688/119688 [==============================] - 26s 217us/step - loss: 0.0885 - acc: 0.7681 - val_loss: 0.0885 - val_acc: 0.7688\n",
      "Epoch 00031: early stopping\n",
      "Done with training cycle 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-b1c845041cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigDaddyLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-f8b10f7db262>\u001b[0m in \u001b[0;36mbigDaddyLearning\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearningCycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearnOnData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done with training cycle \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-73861cee8035>\u001b[0m in \u001b[0;36mgenerateData\u001b[0;34m(N, network, player1)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-5ba0eea30a82>\u001b[0m in \u001b[0;36mgame\u001b[0;34m(network, player1)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# keep playing as long as no one winning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mcheckwin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         '''\n",
      "\u001b[0;32m<ipython-input-10-a96ca78bf423>\u001b[0m in \u001b[0;36mcheckwin\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#look for 4 of a kind on columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwincombopos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0misWin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwincomboneg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/machinelearning/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36marray_equal\u001b[0;34m(a1, a2)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = load_model(\"model1.h5\")\n",
    "\n",
    "\n",
    "\n",
    "model2 = bigDaddyLearning(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the trained classifier\n",
    "model.save('model3.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compete between old and new models to test our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optMove(B, network, player):\n",
    "    poss = possibilities(B, network, player)\n",
    "    \n",
    "    if(player == 1):\n",
    "        myIndex = 0\n",
    "    else:\n",
    "        myIndex=1\n",
    "    \n",
    "    p = poss[0][1][0][myIndex]\n",
    "    opti = 0\n",
    "    for i in range(len(poss)):\n",
    "        pi = poss[i][1][0][myIndex]\n",
    "        if pi > p:\n",
    "            opti = i \n",
    "    \n",
    "    optB = poss[opti][0]\n",
    "                          \n",
    "    return optB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow 2 models to play each other\n",
    "# Network 1 is the player1 \"1\", \"1\" goes first\n",
    "# output who wins \"1\", \"-1\", or a draw \"0\"\n",
    "\n",
    "def compete(network1, network2):\n",
    "    B = newgame()\n",
    "    step = 0\n",
    "    \n",
    "    # keep playing as long as no one winning\n",
    "    while checkwin(B) == 0 and check_draw(B) != True:\n",
    "        step += 1\n",
    "        if (step % 2) == 0: # odd step player1 moves, otherwise player2 moves\n",
    "            B = goodMove(B, -1, network2)\n",
    "        else:\n",
    "            B = goodMove(B, 1, network1)\n",
    "    return checkwin(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return percentage of times player1 win, draw, and player-1 win\n",
    "\n",
    "def competeMultiple(N, network1, network2):\n",
    "    draw  = 0\n",
    "    win1 = 0\n",
    "    win_1 = 0\n",
    "    for i in range(N):\n",
    "        result = compete(network1, network2)\n",
    "        if result == 0:\n",
    "            draw += 1\n",
    "        elif result == 1:\n",
    "            win1 += 1\n",
    "        else:\n",
    "            win_1 += 1\n",
    "    percent = float(win_1)/N\n",
    "    \n",
    "    return percent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check model performance accuracy before\n",
    "model0 = load_model(\"model0.h5\")\n",
    "model1 = load_model(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = load_model(\"model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4405"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competeMultiple(10000, model0, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4416"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competeMultiple(10000, model1, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.431"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competeMultiple(1000, model0, model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.434"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competeMultiple(1000, model3, model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### competeMultiple(1000, model0, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save('model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
